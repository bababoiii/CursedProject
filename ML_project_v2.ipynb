{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "Dm1cF6UNJPzr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Оглавление"
      ],
      "metadata": {
        "id": "IRMy67HLJIOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Часть 0 : Играем в песочнице"
      ],
      "metadata": {
        "id": "SWgpEB9sJHNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Установим все нужные библиотеки"
      ],
      "metadata": {
        "id": "yZ-AGdy4-KcU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWRCT6Taa7Yi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as rnd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import scipy as scp\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import json\n",
        "%matplotlib inline\n",
        "\n",
        "eps = 1e-10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPQ4EmxslWnS",
        "outputId": "cfa4c259-1e3b-4705-a82c-92fb583e9d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пока мы ещё маленькие и совсем ничего не понимаем в нейросетях. Сделаем простую игру (что-то в духе камень-ножницы-бумага), чтобы проверить, работает ли модель в принципе и научится ей пользоваться для более сложной задачи, которая ждёт нас впереди."
      ],
      "metadata": {
        "id": "0LQ5p4UlfLhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def game_1():\n",
        "    ### ЭТАП 1: МОДЕЛЬ ###\n",
        "    model = models.Sequential([\n",
        "        layers.InputLayer(shape=(2,)),  # Вход: 2 героя\n",
        "        layers.Dense(16, activation='relu'),  # Скрытый слой\n",
        "        layers.Dense(1, activation='sigmoid')  # Выход: Победитель (0 или 1)\n",
        "    ])\n",
        "\n",
        "    ### ЭТАП 2: ОБУЧЕНИЕ ###\n",
        "    '''\n",
        "    Генерируем матчи:\n",
        "    a и b - от 1 до 3.\n",
        "    Если они совпадают, то мы их не добавляем (мы пока не рассматриваем ничьи)\n",
        "\n",
        "    '''\n",
        "    X = np.array([\n",
        "        [a, b] for _ in range(1500)\n",
        "        for a, b in [(rnd.randint(1, 3), rnd.randint(1, 3))]\n",
        "        if a != b\n",
        "    ])\n",
        "    Y = np.array([0 if a < b else 1 for a, b in X]) # Номер победившего в паре игрока\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X, Y, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "    ### ЭТАП 3: ТЕСТИРОВАНИЕ ###\n",
        "\n",
        "    # Теперь создадим тестовые игры, чтобы проверить, что нейросеть обучилась\n",
        "    X_test = np.array([\n",
        "        [a, b] for _ in range(10)\n",
        "        for a, b in [(rnd.randint(1, 3), rnd.randint(1, 3))]\n",
        "        if a != b\n",
        "    ])\n",
        "\n",
        "    Y_test = np.array([0 if a < b else 1 for a, b in X_test]) # Правильные ответы\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(int)  # Предсказания нашей модели\n",
        "    errors = 0\n",
        "\n",
        "    # Сравниваем\n",
        "    for i in range(len(y_pred)):\n",
        "        p1 = ['A', 'B', 'C'][X_test[i][0] - 1]\n",
        "        p2 = ['A', 'B', 'C'][X_test[i][1] - 1]\n",
        "        if y_pred[i] != Y_test[i]:\n",
        "            print(f\"Ошибка! {i+1}) {p1} против {p2}, победил не {p2 if y_pred[i] else p1}\")\n",
        "            errors += 1\n",
        "        else:\n",
        "            print(f\"{i+1}) {p1} против {p2} => Победитель: {p2 if y_pred[i] else p1}\")\n",
        "    print(\"Процент ошибок:\", round((errors / len(Y_test)) * 100, 2), \"%\")"
      ],
      "metadata": {
        "id": "HKJclr3D_xd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game_1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WedWR9aGAlsR",
        "outputId": "3c92d87a-44ea-45ce-a1b6-1d796aa95a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "1) B против A => Победитель: A\n",
            "2) B против A => Победитель: A\n",
            "3) A против C => Победитель: A\n",
            "4) B против C => Победитель: B\n",
            "5) C против A => Победитель: A\n",
            "6) A против B => Победитель: A\n",
            "7) B против A => Победитель: A\n",
            "Процент ошибок: 0.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P.s. В дальнейшем мы не будем так подробно расписывать комментарии"
      ],
      "metadata": {
        "id": "J9LcAJSfBVsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Всё работает, отлично - модель научилась угадывать победителя. Теперь напишем, чтобы она сама участвовала в игре и выбирала себе героя."
      ],
      "metadata": {
        "id": "i7v22hosopeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def game_2():\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    ### ЭТАП 1: МОДЕЛЬ ###\n",
        "    def reward(a, b):\n",
        "        return ([a, b] in [[0, 1], [0, 2], [1, 2]]) # 0 всегда выигрывает\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=(1,)), # Вход : заглушка\n",
        "        keras.layers.Dense(3, activation='softmax')  # Выход: 3 героя, p их выбора\n",
        "    ])\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    ### ЭТАП 2: ОБУЧЕНИЕ ###\n",
        "    num_episodes = 300   # Эпохи обучения\n",
        "    games_per_episode = 50    # Матчей за одну эпоху\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Вероятности для хода\n",
        "            state_input = tf.ones((games_per_episode, 1), dtype=tf.float32)\n",
        "            probs = model(state_input, training=True)\n",
        "            log_probs = tf.math.log(probs + eps)\n",
        "\n",
        "            # Генерируем ходы модели\n",
        "            sampled_actions = tf.random.categorical(log_probs, num_samples=1)\n",
        "            sampled_actions = tf.squeeze(sampled_actions, axis=1)\n",
        "\n",
        "            # Считаем награду\n",
        "            rewards = []\n",
        "            for i in range(games_per_episode):\n",
        "                model_hero = sampled_actions[i].numpy()\n",
        "                possible_opp_moves = [x for x in [0,1,2] if x != model_hero]\n",
        "                opp_hero = np.random.choice(possible_opp_moves)\n",
        "                rewards.append(reward(model_hero, opp_hero))\n",
        "\n",
        "            rewards = tf.constant(rewards, dtype=tf.float32)\n",
        "            chosen_action_log_p = tf.reduce_sum(\n",
        "                tf.one_hot(sampled_actions, depth=3) * log_probs,\n",
        "                axis=1\n",
        "            )\n",
        "            loss = -tf.reduce_mean(rewards * chosen_action_log_p)\n",
        "\n",
        "        # Корректируем модель, обновляем веса\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Выводим статистику\n",
        "        if (episode + 1) % 20 == 0:\n",
        "            mean_reward = tf.reduce_mean(rewards)\n",
        "            print(f\"Episode {episode + 1}/{num_episodes} | Mean reward: {round(mean_reward.numpy(), 2)} | Loss: {round(loss.numpy(), 3)}\")\n",
        "\n",
        "    ### ЭТАП 3: ТЕСТИРОВАНИЕ ###\n",
        "    print('-' * 52 + '\\nТестирование\\n' + '-' * 52)\n",
        "    N_test = 1000\n",
        "    test_input = tf.ones((N_test, 1), dtype=tf.float32)\n",
        "    test_probs = model(test_input, training=False)\n",
        "    test_log_probs = tf.math.log(test_probs + 1e-10)\n",
        "    test_actions = tf.random.categorical(test_log_probs, num_samples=1)\n",
        "    test_actions = tf.squeeze(test_actions, axis=1).numpy()\n",
        "\n",
        "    wins = 0\n",
        "    L = ['A', 'B', 'C']\n",
        "    for i in range(N_test):\n",
        "        model_hero = test_actions[i]\n",
        "        opp_hero = np.random.choice([x for x in [0, 1, 2] if x != model_hero])\n",
        "        if reward(model_hero, opp_hero):\n",
        "            wins += 1\n",
        "            if i % 50 == 0:\n",
        "                print(f\"Модель с героем {L[model_hero]} обыграла героя соперника {L[opp_hero]}\")\n",
        "        else:\n",
        "            if i % 50 == 0:\n",
        "                print(f\"x - Модель с героем {L[model_hero]} проиграла герою соперника {L[opp_hero]}\")\n",
        "\n",
        "    win_percent = 100.0 * wins / N_test\n",
        "    print(f\"\\nРезультат: модель выиграла в {round(win_percent, 2)}% случаев.\")"
      ],
      "metadata": {
        "id": "kneotJNv2Q51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game_2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaBO80XpCVWc",
        "outputId": "aa7ccc67-5742-44b1-8631-bfac236b9614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20/300 | Mean reward: 0.8199999928474426 | Loss: 0.46799999475479126\n",
            "Episode 40/300 | Mean reward: 0.8399999737739563 | Loss: 0.21899999678134918\n",
            "Episode 60/300 | Mean reward: 0.8999999761581421 | Loss: 0.21199999749660492\n",
            "Episode 80/300 | Mean reward: 0.9599999785423279 | Loss: 0.13699999451637268\n",
            "Episode 100/300 | Mean reward: 0.9800000190734863 | Loss: 0.125\n",
            "Episode 120/300 | Mean reward: 0.9399999976158142 | Loss: 0.11500000208616257\n",
            "Episode 140/300 | Mean reward: 0.9800000190734863 | Loss: 0.03799999877810478\n",
            "Episode 160/300 | Mean reward: 0.9599999785423279 | Loss: 0.03099999949336052\n",
            "Episode 180/300 | Mean reward: 0.9800000190734863 | Loss: 0.10700000077486038\n",
            "Episode 200/300 | Mean reward: 0.9800000190734863 | Loss: 0.10599999874830246\n",
            "Episode 220/300 | Mean reward: 1.0 | Loss: 0.10700000077486038\n",
            "Episode 240/300 | Mean reward: 1.0 | Loss: 0.017000000923871994\n",
            "Episode 260/300 | Mean reward: 1.0 | Loss: 0.01600000075995922\n",
            "Episode 280/300 | Mean reward: 1.0 | Loss: 0.014000000432133675\n",
            "Episode 300/300 | Mean reward: 1.0 | Loss: 0.013000000268220901\n",
            "----------------------------------------------------\n",
            "Тестирование\n",
            "----------------------------------------------------\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "x - Модель с героем B проиграла герою соперника A\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "\n",
            "Результат: модель выиграла в 99.3% случаев.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "УРААААА ГОООООЛ, он что-то выиграл.\n",
        "Это здорово, что он придумал невероятную тактику всегда выбирать героя А, но что, если правила С будет бить А, а не наоборот. Да и вообще, пора матрицу игр писать, ничью добавить...\n",
        "А ещё устроим дополнительную проверку модели на адекватность - нужно будет выбирать свой ход исходя из хода соперника (\"если у соперника ножницы, то очевидно нужен камень\", и т.д.)\n",
        "\n",
        "p.s. можно заметить, что это уже немного похоже на задачу, которую нам предстоит решить"
      ],
      "metadata": {
        "id": "kXFFnVSuXpyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ОБУЧЕНИЕ"
      ],
      "metadata": {
        "id": "o6F-aLIug90N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def game_3():\n",
        "    ### ЭТАП 1 : МОДЕЛЬ ###\n",
        "\n",
        "    '''\n",
        "     Матрица выигрышей:\n",
        "    0.5 – ничья, 1 – победа, 0 – поражение\n",
        "    '''\n",
        "    matrix = [[0.5, 1, 0], [0, 0.5, 1], [1, 0, 0.5]]\n",
        "    def reward(a, b):\n",
        "        return matrix[a][b]\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=(1,)), # Вход : 1 герой соперника\n",
        "        keras.layers.Embedding(input_dim=3, output_dim=4), # ДОПИСАТЬ\n",
        "        keras.layers.Flatten(), # ДОПИСАТЬ\n",
        "        keras.layers.Dense(3, activation='softmax')  # Выход: 3 героя, p их выбора\n",
        "    ])\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    ### ЭТАП 2 : ОБУЧЕНИЕ ###\n",
        "    num_episodes = 300   # Эпохи обучения\n",
        "    games_per_episode = 50    # Матчей за одну эпоху\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Ходы соперника\n",
        "            opp_hero = np.random.randint(0, 3, size=games_per_episode)\n",
        "\n",
        "            # Ходы модели\n",
        "            state_input = tf.constant(opp_hero, dtype=tf.float32)\n",
        "            state_input = tf.reshape(state_input, (games_per_episode, 1))\n",
        "            probs = model(state_input, training=True)\n",
        "            log_probs = tf.math.log(probs + eps)\n",
        "            sampled_actions = tf.random.categorical(log_probs, num_samples=1)\n",
        "            sampled_actions = tf.squeeze(sampled_actions, axis=1)\n",
        "\n",
        "            # Награда\n",
        "            rewards = []\n",
        "            for i in range(games_per_episode):\n",
        "                model_hero = sampled_actions[i].numpy()\n",
        "                rewards.append(reward(model_hero, opp_hero[i]))\n",
        "\n",
        "            rewards = tf.constant(rewards, dtype=tf.float32)\n",
        "            chosen_action_log_p = tf.reduce_sum(\n",
        "                tf.one_hot(sampled_actions, depth=3) * log_probs,\n",
        "                axis=1\n",
        "            )\n",
        "            loss = -tf.reduce_mean(rewards * chosen_action_log_p)\n",
        "\n",
        "        # Корректировка\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Статистика\n",
        "        if (episode + 1) % 20 == 0:\n",
        "            mean_reward = tf.reduce_mean(rewards)\n",
        "            print(f\"Episode {episode+1}/{num_episodes} | Mean reward: {round(mean_reward.numpy(), 2)} | Loss: {round(loss.numpy(), 3)}\")\n",
        "\n",
        "    ### ЭТАП 3 : ТЕСТИРОВАНИЕ ###\n",
        "    print('-' * 52 + '\\nТестирование\\n' + '-' * 52)\n",
        "    N_test = 1000\n",
        "    opp_hero_test = np.random.randint(0, 3, size=N_test)\n",
        "    test_input = tf.constant(opp_hero_test, dtype=tf.float32)\n",
        "    test_input = tf.reshape(test_input, (N_test, 1))\n",
        "\n",
        "    test_probs = model(test_input, training=False)\n",
        "    test_log_probs = tf.math.log(test_probs + eps)\n",
        "    test_actions = tf.random.categorical(test_log_probs, num_samples=1)\n",
        "    test_actions = tf.squeeze(test_actions, axis=1).numpy()\n",
        "\n",
        "    wins = 0\n",
        "    L = ['A', 'B', 'C']\n",
        "    for i in range(N_test):\n",
        "        model_hero = test_actions[i]\n",
        "        opp_hero = opp_hero_test[i]\n",
        "        r = reward(model_hero, opp_hero)\n",
        "        wins += r\n",
        "        if i % 50 == 0 or r < 1:\n",
        "            if r == 1.0:\n",
        "                print(f\"Модель с героем {L[model_hero]} обыграла героя соперника {L[opp_hero]}\")\n",
        "            elif r:\n",
        "                print(f\"Модель с героем {L[model_hero]} сыграла вничью с героем соперника {L[opp_hero]}\")\n",
        "            else:\n",
        "                print(f\"Ошибка! Модель с героем {L[model_hero]} проиграла герою соперника {L[opp_hero]}\")\n",
        "\n",
        "    win_percent = 100.0 * wins / N_test\n",
        "    print(f\"\\nИтоговая проверка: модель выиграла в {round(win_percent, 2)}% матчей.\")"
      ],
      "metadata": {
        "id": "AZ8KS7WyVCQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game_3()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwPiV7TjZ_B4",
        "outputId": "a18262c5-8414-4f47-d898-7821c7b8feb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20/300 | Mean reward: 0.49000000953674316 | Loss: 0.3959999978542328\n",
            "Episode 40/300 | Mean reward: 0.8299999833106995 | Loss: 0.31299999356269836\n",
            "Episode 60/300 | Mean reward: 0.8999999761581421 | Loss: 0.164000004529953\n",
            "Episode 80/300 | Mean reward: 1.0 | Loss: 0.020999999716877937\n",
            "Episode 100/300 | Mean reward: 0.9900000095367432 | Loss: 0.05900000035762787\n",
            "Episode 120/300 | Mean reward: 1.0 | Loss: 0.006000000052154064\n",
            "Episode 140/300 | Mean reward: 1.0 | Loss: 0.004999999888241291\n",
            "Episode 160/300 | Mean reward: 1.0 | Loss: 0.004000000189989805\n",
            "Episode 180/300 | Mean reward: 0.9900000095367432 | Loss: 0.06300000101327896\n",
            "Episode 200/300 | Mean reward: 1.0 | Loss: 0.003000000026077032\n",
            "Episode 220/300 | Mean reward: 1.0 | Loss: 0.0020000000949949026\n",
            "Episode 240/300 | Mean reward: 1.0 | Loss: 0.0020000000949949026\n",
            "Episode 260/300 | Mean reward: 1.0 | Loss: 0.0010000000474974513\n",
            "Episode 280/300 | Mean reward: 1.0 | Loss: 0.0010000000474974513\n",
            "Episode 300/300 | Mean reward: 1.0 | Loss: 0.0010000000474974513\n",
            "----------------------------------------------------\n",
            "Тестирование\n",
            "----------------------------------------------------\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A сыграла вничью с героем соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "\n",
            "Итоговая проверка: модель выиграла в 99.95% матчей.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Потрясающе, какие мы молодцы.\n",
        "Теперь представим, что героев у нас не 3, а там, 200. А ещё мы живём в реальном мире, где и везде и повсюду вероятности, так, что есть шанс у героя в неравной схватке с другим изредка выйти победителем.\n",
        "\n",
        "Все эти вероятности мы учтём в нашей матрице, а после этого проверим нашу модель на работоспособность в самых что ни на есть боевых условиях"
      ],
      "metadata": {
        "id": "MO7LPKoNnLPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def game_4(matrix, hero_number=200):\n",
        "    ### ЭТАП 1 : МОДЕЛЬ ###\n",
        "    def reward(a, b):\n",
        "        return 1 if rnd.random() < matrix[a][b] else 0\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Input(shape=(1,)), # Вход : 1 герой соперника\n",
        "        keras.layers.Embedding(input_dim=hero_number, output_dim=hero_number+1),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(hero_number, activation='softmax')\n",
        "    ])\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "    ### ЭТАП 2 : ОБУЧЕНИЕ ###\n",
        "    num_episodes = 300   # Эпохи обучения\n",
        "    games_per_episode = 50    # Матчей за одну эпоху\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Ходы соперника\n",
        "            opp_hero = np.random.randint(0, hero_number, size=games_per_episode)\n",
        "\n",
        "            # Ходы модели\n",
        "            state_input = tf.constant(opp_hero, dtype=tf.float32)\n",
        "            state_input = tf.reshape(state_input, (games_per_episode, 1))\n",
        "            probs = model(state_input, training=True)\n",
        "            log_probs = tf.math.log(probs + eps)\n",
        "            sampled_actions = tf.random.categorical(log_probs, num_samples=1)\n",
        "            sampled_actions = tf.squeeze(sampled_actions, axis=1)\n",
        "\n",
        "            # Награда\n",
        "            rewards = []\n",
        "            for i in range(games_per_episode):\n",
        "                model_hero = sampled_actions[i].numpy()\n",
        "                rewards.append(reward(model_hero, opp_hero[i]))\n",
        "\n",
        "            rewards = tf.constant(rewards, dtype=tf.float32)\n",
        "            chosen_action_log_p = tf.reduce_sum(\n",
        "                tf.one_hot(sampled_actions, depth=hero_number) * log_probs,\n",
        "                axis=1\n",
        "            )\n",
        "            loss = -tf.reduce_mean(rewards * chosen_action_log_p)\n",
        "\n",
        "        # Корректировка\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Статистика\n",
        "        if (episode + 1) % 20 == 0:\n",
        "            mean_reward = tf.reduce_mean(rewards)\n",
        "            print(f\"Episode {episode+1}/{num_episodes} | Mean reward: {round(mean_reward.numpy(),2)} | Loss: {round(loss.numpy(),3)}\")\n",
        "\n",
        "    ### ЭТАП 3 : ТЕСТИРОВАНИЕ ###\n",
        "    print('-' * 52 + '\\nТестирование\\n' + '-' * 52)\n",
        "    N_test = 1000\n",
        "    print(hero_number)\n",
        "    opp_hero_test = np.random.randint(0, hero_number, size=N_test)\n",
        "    test_input = tf.constant(opp_hero_test, dtype=tf.float32)\n",
        "    test_input = tf.reshape(test_input, (N_test, 1))\n",
        "\n",
        "    test_probs = model(test_input, training=False)\n",
        "    test_log_probs = tf.math.log(test_probs + eps)\n",
        "    test_actions = tf.random.categorical(test_log_probs, num_samples=1)\n",
        "    test_actions = tf.squeeze(test_actions, axis=1).numpy()\n",
        "\n",
        "    wins = 0\n",
        "    L = [chr(i + 100) for i in range(hero_number)]\n",
        "    for i in range(N_test):\n",
        "        model_hero = test_actions[i]\n",
        "        opp_hero = opp_hero_test[i]\n",
        "        r = reward(model_hero, opp_hero)\n",
        "        wins += r\n",
        "        if i % 50 == 0:\n",
        "            if r:\n",
        "                print(f\"Модель с героем {L[model_hero]} обыграла героя соперника {L[opp_hero]}\")\n",
        "            else:\n",
        "                print(f\"Ошибка! Модель с героем {L[model_hero]} проиграла герою соперника {L[opp_hero]}\")\n",
        "\n",
        "    win_percent = 100.0 * wins / N_test\n",
        "    print(f\"\\nИтоговая проверка: модель выиграла в {round(win_percent,2)}% матчей.\")"
      ],
      "metadata": {
        "id": "DQrf9dq4e3HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hero_number = 200\n",
        "matrix = [[rnd.random() * 0.8 for _ in range(hero_number)] for __ in range(hero_number)]\n",
        "for i in range(hero_number):\n",
        "    matrix[i][i] = 0.5\n",
        "    for j in range(i+1, hero_number):\n",
        "        matrix[i][j] = 1 - matrix[j][i]\n",
        "game_4(matrix, hero_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4RE92Ule-RK",
        "outputId": "01ef82b9-0e74-46f9-a67a-747f0e3c4857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20/300 | Mean reward: 0.6200000047683716 | Loss: 3.2869999408721924\n",
            "Episode 40/300 | Mean reward: 0.47999998927116394 | Loss: 2.5269999504089355\n",
            "Episode 60/300 | Mean reward: 0.46000000834465027 | Loss: 2.5179998874664307\n",
            "Episode 80/300 | Mean reward: 0.5400000214576721 | Loss: 2.8589999675750732\n",
            "Episode 100/300 | Mean reward: 0.6000000238418579 | Loss: 3.11299991607666\n",
            "Episode 120/300 | Mean reward: 0.5199999809265137 | Loss: 2.4019999504089355\n",
            "Episode 140/300 | Mean reward: 0.5600000023841858 | Loss: 2.4560000896453857\n",
            "Episode 160/300 | Mean reward: 0.6000000238418579 | Loss: 2.2049999237060547\n",
            "Episode 180/300 | Mean reward: 0.5400000214576721 | Loss: 1.5839999914169312\n",
            "Episode 200/300 | Mean reward: 0.6000000238418579 | Loss: 1.3680000305175781\n",
            "Episode 220/300 | Mean reward: 0.6399999856948853 | Loss: 0.6629999876022339\n",
            "Episode 240/300 | Mean reward: 0.6399999856948853 | Loss: 0.7419999837875366\n",
            "Episode 260/300 | Mean reward: 0.6600000262260437 | Loss: 0.10999999940395355\n",
            "Episode 280/300 | Mean reward: 0.8600000143051147 | Loss: 0.2150000035762787\n",
            "Episode 300/300 | Mean reward: 0.6800000071525574 | Loss: 0.09399999678134918\n",
            "----------------------------------------------------\n",
            "Тестирование\n",
            "----------------------------------------------------\n",
            "200\n",
            "Ошибка! Модель с героем ¿ проиграла герою соперника µ\n",
            "Модель с героем  обыграла героя соперника ³\n",
            "Модель с героем ì обыграла героя соперника ÷\n",
            "Модель с героем t обыграла героя соперника đ\n",
            "Модель с героем Ó обыграла героя соперника }\n",
            "Ошибка! Модель с героем ü проиграла герою соперника p\n",
            "Модель с героем ā обыграла героя соперника Ã\n",
            "Ошибка! Модель с героем õ проиграла герою соперника ¡\n",
            "Модель с героем ď обыграла героя соперника à\n",
            "Модель с героем Ê обыграла героя соперника ù\n",
            "Модель с героем Ù обыграла героя соперника ĩ\n",
            "Модель с героем | обыграла героя соперника ~\n",
            "Модель с героем ­ обыграла героя соперника Ü\n",
            "Модель с героем č обыграла героя соперника }\n",
            "Модель с героем č обыграла героя соперника Ě\n",
            "Модель с героем  обыграла героя соперника \n",
            "Модель с героем  обыграла героя соперника á\n",
            "Ошибка! Модель с героем £ проиграла герою соперника  \n",
            "Модель с героем ď обыграла героя соперника \n",
            "Модель с героем u обыграла героя соперника û\n",
            "\n",
            "Итоговая проверка: модель выиграла в 74.9% матчей.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промежуточные итоги : умеем угадывать исход матчей и выбирать оптимального героя под выбор соперника.\n",
        "\n",
        "Дальше - больше!"
      ],
      "metadata": {
        "id": "Da9xhk9SfJ7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Часть 1 : Парсим датасет"
      ],
      "metadata": {
        "id": "Dm1cF6UNJPzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Heroes = []\n",
        "Heroes_id = {}\n",
        "\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/data/heroes.zip', 'r') as archive:\n",
        "    with archive.open('heroes.json') as f:\n",
        "        heroes_data = json.load(f)\n",
        "hero_num = 146\n",
        "Heroes = [None] * hero_num\n",
        "\n",
        "for hero in heroes_data:\n",
        "    hero_id = hero['hero_id']\n",
        "    name = hero['name']\n",
        "    Heroes[hero_id] = name\n",
        "    Heroes_id[name] = hero_id\n",
        "\n",
        "\n",
        "print(\"Heroes:\", Heroes)\n",
        "print(\"Heroes_id:\", Heroes_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbwSafEOtEM7",
        "outputId": "db36c92b-c7cd-41cd-9033-f5236c36bee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heroes: [None, 'antimage', 'axe', 'crystal-maiden', 'dazzle', 'drow-ranger', 'earthshaker', 'lich', 'lina', 'lion', 'mirana', 'morphling', 'necrophos', 'puck', 'pudge', 'razor', 'sand-king', 'shadow-shaman', 'storm-spirit', 'sven', 'tidehunter', 'vengefulspirit', 'windranger', 'witch-doctor', 'zeus', 'slardar', 'enigma', 'faceless-void', 'tiny', 'viper', 'venomancer', 'clockwerk', 'natures-prophet', 'dark-seer', 'sniper', 'beastmaster', 'pugna', 'enchantress', 'leshrac', 'shadow-fiend', 'tinker', 'weaver', 'night-stalker', 'ancient-apparition', 'spectre', 'doom', 'juggernaut', 'bloodseeker', 'riki', 'kunkka', 'chen', 'queenofpain', 'wraith-king', 'broodmother', 'huskar', 'jakiro', 'batrider', 'omniknight', 'dragon-knight', 'warlock', 'alchemist', 'life-stealer', 'death-prophet', 'ursa', 'bounty-hunter', 'silencer', 'spirit-breaker', 'invoker', 'clinkz', 'outworld-destroyer', 'bane', 'shadow-demon', 'lycan', 'lone-druid', 'brewmaster', 'phantom-lancer', 'treant', 'ogre-magi', 'gyrocopter', 'chaos-knight', 'phantom-assassin', 'rubick', 'luna', 'io', 'undying', 'disruptor', 'templar-assassin', 'naga-siren', 'nyx-assassin', 'keeper-of-the-light', 'visage', 'meepo', 'magnus', 'centaur', 'slark', 'timbersaw', 'medusa', 'troll-warlord', 'tusk', 'bristleback', 'skywrath-mage', 'elder-titan', 'abaddon', 'ember-spirit', 'earth-spirit', 'legion-commander', 'phoenix', 'terrorblade', 'techies', 'oracle', 'winter-wyvern', 'arc-warden', 'underlord', 'monkey-king', 'dark-willow', 'pangolier', 'grimstroke', 'mars', 'snapfire', 'void-spirit', 'hoodwink', 'dawnbreaker', 'marci', 'primal-beast', 'muerta', None, 'kez', None, None, None, None, 'ringmaster', None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
            "Heroes_id: {'antimage': 1, 'mirana': 10, 'morphling': 11, 'necrophos': 12, 'puck': 13, 'pudge': 14, 'razor': 15, 'sand-king': 16, 'shadow-shaman': 17, 'storm-spirit': 18, 'sven': 19, 'axe': 2, 'tidehunter': 20, 'vengefulspirit': 21, 'windranger': 22, 'witch-doctor': 23, 'zeus': 24, 'crystal-maiden': 3, 'dazzle': 4, 'drow-ranger': 5, 'earthshaker': 6, 'lich': 7, 'lina': 8, 'lion': 9, 'slardar': 25, 'enigma': 26, 'faceless-void': 27, 'tiny': 28, 'viper': 29, 'venomancer': 30, 'clockwerk': 31, 'natures-prophet': 32, 'dark-seer': 33, 'sniper': 34, 'beastmaster': 35, 'pugna': 36, 'enchantress': 37, 'leshrac': 38, 'shadow-fiend': 39, 'tinker': 40, 'weaver': 41, 'night-stalker': 42, 'ancient-apparition': 43, 'spectre': 44, 'doom': 45, 'chen': 50, 'juggernaut': 46, 'bloodseeker': 47, 'kunkka': 49, 'riki': 48, 'queenofpain': 51, 'wraith-king': 52, 'broodmother': 53, 'huskar': 54, 'jakiro': 55, 'batrider': 56, 'omniknight': 57, 'dragon-knight': 58, 'warlock': 59, 'alchemist': 60, 'life-stealer': 61, 'death-prophet': 62, 'ursa': 63, 'bounty-hunter': 64, 'silencer': 65, 'spirit-breaker': 66, 'invoker': 67, 'clinkz': 68, 'outworld-destroyer': 69, 'bane': 70, 'shadow-demon': 71, 'lycan': 72, 'lone-druid': 73, 'brewmaster': 74, 'phantom-lancer': 75, 'treant': 76, 'ogre-magi': 77, 'gyrocopter': 78, 'chaos-knight': 79, 'phantom-assassin': 80, 'rubick': 81, 'luna': 82, 'io': 83, 'undying': 84, 'disruptor': 85, 'templar-assassin': 86, 'naga-siren': 87, 'nyx-assassin': 88, 'keeper-of-the-light': 89, 'visage': 90, 'meepo': 91, 'magnus': 92, 'centaur': 93, 'slark': 94, 'timbersaw': 95, 'medusa': 96, 'troll-warlord': 97, 'tusk': 98, 'bristleback': 99, 'skywrath-mage': 100, 'elder-titan': 101, 'abaddon': 102, 'ember-spirit': 103, 'earth-spirit': 104, 'legion-commander': 105, 'phoenix': 106, 'terrorblade': 107, 'techies': 108, 'oracle': 109, 'winter-wyvern': 110, 'arc-warden': 111, 'underlord': 112, 'monkey-king': 113, 'dark-willow': 114, 'pangolier': 115, 'grimstroke': 116, 'mars': 117, 'snapfire': 118, 'void-spirit': 119, 'hoodwink': 120, 'dawnbreaker': 121, 'marci': 122, 'primal-beast': 123, 'muerta': 124, 'ringmaster': 131, 'kez': 126}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile('/content/drive/MyDrive/data/parsed_matches.zip', 'r') as archive:\n",
        "    with archive.open('parsed_matches.json') as f:\n",
        "        matches_data = json.load(f)\n",
        "print(len(matches_data), len(matches_data[0]))\n",
        "print(matches_data[0])\n",
        "#print(json.dumps(matches_data[0], indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqx2WjKzt27W",
        "outputId": "92b445b9-31e0-483e-a78e-a6d982e2275e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6895 10\n",
            "{'match_id': '8229805524', 'radiant_team_name': 'Силы Света', 'dire_team_name': 'Силы Тьмы', 'radiant_heroes': ['32', '7', '100', '9', '27'], 'dire_heroes': ['2', '93', '37', '95', '14'], 'radiant_players_info': [{'hero_id': 32, 'kills': 8, 'deaths': 3, 'assists': 6, 'gold_per_min': 1094, 'xp_per_min': 1516, 'last_hits': 74, 'hero_damage': 15718, 'tower_damage': 0, 'kda': ''}, {'hero_id': 7, 'kills': 1, 'deaths': 2, 'assists': 8, 'gold_per_min': 775, 'xp_per_min': 1170, 'last_hits': 78, 'hero_damage': 11488, 'tower_damage': 54, 'kda': ''}, {'hero_id': 100, 'kills': 4, 'deaths': 8, 'assists': 8, 'gold_per_min': 828, 'xp_per_min': 1323, 'last_hits': 57, 'hero_damage': 13989, 'tower_damage': 0, 'kda': ''}, {'hero_id': 9, 'kills': 2, 'deaths': 1, 'assists': 10, 'gold_per_min': 879, 'xp_per_min': 1156, 'last_hits': 92, 'hero_damage': 5310, 'tower_damage': 0, 'kda': ''}, {'hero_id': 27, 'kills': 5, 'deaths': 5, 'assists': 3, 'gold_per_min': 978, 'xp_per_min': 1152, 'last_hits': 112, 'hero_damage': 9736, 'tower_damage': 2422, 'kda': ''}], 'dire_players_info': [{'hero_id': 2, 'kills': 3, 'deaths': 4, 'assists': 6, 'gold_per_min': 1008, 'xp_per_min': 1387, 'last_hits': 79, 'hero_damage': 9434, 'tower_damage': 431, 'kda': ''}, {'hero_id': 93, 'kills': 3, 'deaths': 3, 'assists': 8, 'gold_per_min': 1074, 'xp_per_min': 1429, 'last_hits': 97, 'hero_damage': 12273, 'tower_damage': 2853, 'kda': ''}, {'hero_id': 37, 'kills': 3, 'deaths': 4, 'assists': 9, 'gold_per_min': 999, 'xp_per_min': 1056, 'last_hits': 67, 'hero_damage': 8859, 'tower_damage': 5301, 'kda': ''}, {'hero_id': 95, 'kills': 5, 'deaths': 5, 'assists': 8, 'gold_per_min': 1311, 'xp_per_min': 1521, 'last_hits': 115, 'hero_damage': 10096, 'tower_damage': 13242, 'kda': ''}, {'hero_id': 14, 'kills': 5, 'deaths': 5, 'assists': 6, 'gold_per_min': 901, 'xp_per_min': 1219, 'last_hits': 45, 'hero_damage': 7397, 'tower_damage': 717, 'kda': ''}], 'winner': True, 'radiant_score': 21, 'dire_score': 19}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_counter = 0\n",
        "def validation_check():\n",
        "    global valid_counter, matches_data\n",
        "    valid_matches = []\n",
        "    for match in matches_data:\n",
        "        try:\n",
        "            radiant = [int(x) for x in match['radiant_heroes']]\n",
        "            dire = [int(x) for x in match['dire_heroes']]\n",
        "        except ValueError:\n",
        "            continue\n",
        "        if min(radiant + dire) == 0:\n",
        "            continue\n",
        "        if len(match['radiant_heroes']) != 5 or len(match['dire_heroes']) != 5:\n",
        "            continue\n",
        "        valid_counter += 1\n",
        "        valid_matches.append(match)\n",
        "    matches_data = valid_matches\n",
        "\n",
        "\n",
        "def build_matrix(data):\n",
        "    for match in data:\n",
        "        try:\n",
        "            radiant = [int(x) for x in match['radiant_heroes']]\n",
        "            dire = [int(x) for x in match['dire_heroes']]\n",
        "        except Exception:\n",
        "            print(f'Exception in build matrix = {Exception}')\n",
        "            continue\n",
        "        for w in radiant:\n",
        "            for l in dire:\n",
        "                matrix[w][l] += 1\n",
        "\n",
        "\n",
        "def normalize_matrix():\n",
        "    n = len(matrix)\n",
        "    for i in range(n):\n",
        "        if matrix[i][i]:\n",
        "            print(\"КАК?\", i, matrix[i][i])\n",
        "        for j in range(i + 1, n):\n",
        "            total = matrix[i][j] + matrix[j][i]\n",
        "            if total:\n",
        "                matrix[i][j] = matrix[i][j] / total\n",
        "                matrix[j][i] = matrix[j][i] / total\n",
        "\n",
        "\n",
        "def matrix_printer(n):\n",
        "    header = \" \" * 17\n",
        "    for j in range(1, n + 1):\n",
        "        header += f\"Hero {j:<5}\"\n",
        "    print(header)\n",
        "    for i in range(1, n + 1):\n",
        "        row = f\"Hero {i:<8}\"\n",
        "        for j in range(1, n + 1):\n",
        "            row += f\"{matrix[i][j]:10.4f}\"\n",
        "        print(row)"
      ],
      "metadata": {
        "id": "eNFrxSrhxDKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_check()\n",
        "print(f\"\\nКоличество валидных результатов = {valid_counter}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xf4B-I-2xuBk",
        "outputId": "012cc699-798c-41f9-d1b6-8e8ced1e8461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Количество валидных результатов = 6836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Часть 2 : Обучаем модель"
      ],
      "metadata": {
        "id": "BKjBtnlCJUyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чем мы будем здесь заниматься?\n",
        "\n",
        "Ну, для начала, мы хотим, чтобы модель правильно угадывала исход матчей, основываясь на персонажах в пике."
      ],
      "metadata": {
        "id": "gjMWaIinoiHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnd.shuffle(matches_data)\n",
        "split_idx = int(0.8 * len(matches_data))\n",
        "match_train = matches_data[:split_idx]\n",
        "match_test = matches_data[split_idx:]\n",
        "print(f'{len(match_train)} тренировочных и {len(match_test)} тестовых матчей')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z68qyQunqRW8",
        "outputId": "1f794d7e-52d4-419a-efcf-8d5421d06931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5468 тренировочных и 1368 тестовых матчей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Постараемся воспользоваться нашими предыдущими наработками. Напишем матрицу \"матчапов\" героев, и постараемся обучить на ней модель."
      ],
      "metadata": {
        "id": "IDe9ZPKP1CFb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " ДОПИСАТЬ"
      ],
      "metadata": {
        "id": "9pUL890C1Mdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = [[0 for _ in range(hero_num)] for _ in range(hero_num)]\n",
        "\n",
        "build_matrix(matches_data[:split_idx])\n",
        "normalize_matrix()\n",
        "matrix_printer(7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnwbF21r1JrT",
        "outputId": "2ea37d20-68a1-485b-a3e1-c88036d23306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Hero 1    Hero 2    Hero 3    Hero 4    Hero 5    Hero 6    Hero 7    \n",
            "Hero 1           0.0000    0.5273    0.1818    0.2500    0.4906    0.3478    0.4098\n",
            "Hero 2           0.4727    0.0000    0.4286    0.5000    0.4583    0.5128    0.4000\n",
            "Hero 3           0.8182    0.5714    0.0000    0.0000    0.6667    0.4000    0.5000\n",
            "Hero 4           0.7500    0.5000    1.0000    0.0000    0.4615    0.5625    0.3889\n",
            "Hero 5           0.5094    0.5417    0.3333    0.5385    0.0000    0.4237    0.5102\n",
            "Hero 6           0.6522    0.4872    0.6000    0.4375    0.5763    0.0000    0.4821\n",
            "Hero 7           0.5902    0.6000    0.5000    0.6111    0.4898    0.5179    0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P.S. Напишем ещё общую функцию, которая будет получать на вход героев и возвращать вектор из 0, 1 и -1 в зависимости от команды"
      ],
      "metadata": {
        "id": "arE8L8fwdNSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_team(radiant_heroes, dire_heroes, hero_number=200):\n",
        "    vector = np.zeros(hero_number)\n",
        "    for hero in radiant_heroes:\n",
        "        vector[int(hero) - 1] = 1\n",
        "    for hero in dire_heroes:\n",
        "        vector[int(hero) - 1] = -1\n",
        "    return vector"
      ],
      "metadata": {
        "id": "mPndHhGUdNoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь к коду ДОПИСАТЬ КОММЕНТАРИИ"
      ],
      "metadata": {
        "id": "8zl3YwAkdM8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_game_1(matrix, hero_number=200):\n",
        "    ### ПОДГОТОВКА ВХОДНЫХ ДАННЫХ ###\n",
        "    local_hero_ids = []\n",
        "    for i in range(len(matrix)):\n",
        "        if any(val != 0 for val in matrix[i]):\n",
        "            local_hero_ids.append(i)\n",
        "    X = []\n",
        "    Y = []\n",
        "    num_samples = 2000\n",
        "    for _ in range(num_samples):\n",
        "        team1 = rnd.sample(local_hero_ids, 5)\n",
        "        team2 = rnd.sample([h for h in local_hero_ids if h not in team1], 5)\n",
        "        radiant_ids = [h + 1 for h in team1]\n",
        "        dire_ids = [h + 1 for h in team2]\n",
        "        vec = vectorize_team(radiant_ids, dire_ids, hero_number)\n",
        "        X.append(vec)\n",
        "\n",
        "        total = sum(matrix[a][b] for a in team1 for b in team2)\n",
        "        Y.append(0 if total > 0 else 1)\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "    ### МОДЕЛЬ И ОБУЧЕНИЕ ###\n",
        "    model = models.Sequential([\n",
        "        layers.InputLayer(shape=(hero_number,)),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(X, Y, epochs=60, batch_size=10, verbose=0)\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict_test_1(model, match_test, hero_number=200):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for match in match_test:\n",
        "        radiant = list(map(int, match['radiant_heroes']))\n",
        "        dire = list(map(int, match['dire_heroes']))\n",
        "        winner = 1 if match['winner'] else 0\n",
        "        vector = vectorize_team(radiant, dire, hero_number)\n",
        "        prediction = model.predict(vector.reshape(1, -1), verbose=0)[0][0]\n",
        "        predicted_label = int(prediction >= 0.5)\n",
        "        if predicted_label == winner:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    print(f\"Точность: {round((correct / total) * 100, 2)}%\")"
      ],
      "metadata": {
        "id": "lzXEntH25szN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_pr_g1 = predict_game_1(matrix, hero_num)\n",
        "predict_test_1(model_pr_g1, match_test, hero_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltSYRRrQnWJq",
        "outputId": "8f87944f-d3ab-455f-a5f9-748f3e1ea575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность: 55.56%\n"
          ]
        }
      ]
    }
  ]
}