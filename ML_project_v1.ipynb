{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWRCT6Taa7Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80a914c6-e3b9-4d76-d81b-057cbeaac203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
            "  from jax import xla_computation as _xla_computation\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import deque\n",
        "import random as rnd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пока мы ещё маленькие и совсем ничего не понимаем в нейросетях. Сделаем простую игру (что-то в духе камень-ножницы-бумага), чтобы проверить, работает ли модель в принципе и научится ей пользоваться для более сложной задачи, которая ждёт нас впереди."
      ],
      "metadata": {
        "id": "0LQ5p4UlfLhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([\n",
        "    [a, b] for _ in range(1500)\n",
        "    for a, b in [(rnd.randint(1, 3), rnd.randint(1, 3))]\n",
        "    if a != b\n",
        "]) # матчи\n",
        "\n",
        "y = np.array([0 if a < b else 1 for a, b in X]) # номер победившего в паре игрока\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.InputLayer(input_shape=(2,)),  # вход: пара героев\n",
        "    layers.Dense(16, activation='relu'),  # скрытый слой\n",
        "    layers.Dense(1, activation='sigmoid')  # выход: победитель (0 или 1)\n",
        "])\n",
        "\n",
        "# компилируем модель\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# обучаем модель\n",
        "model.fit(X, y, epochs=50, batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d4jBL7DCgxYH",
        "outputId": "7f8564a7-4da1-4bcd-d39a-c9a874dd477f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7066 - loss: 0.5500\n",
            "Epoch 2/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.3964\n",
            "Epoch 3/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.2801\n",
            "Epoch 4/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 0.1880\n",
            "Epoch 5/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.1231\n",
            "Epoch 6/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0854\n",
            "Epoch 7/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0624\n",
            "Epoch 8/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0444\n",
            "Epoch 9/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0340\n",
            "Epoch 10/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0268\n",
            "Epoch 11/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0214\n",
            "Epoch 12/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0176\n",
            "Epoch 13/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0141\n",
            "Epoch 14/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0117\n",
            "Epoch 15/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0101\n",
            "Epoch 16/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0085\n",
            "Epoch 17/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0071\n",
            "Epoch 18/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0065\n",
            "Epoch 19/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0056\n",
            "Epoch 20/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0049\n",
            "Epoch 21/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0045\n",
            "Epoch 22/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Epoch 23/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0035\n",
            "Epoch 24/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 25/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 26/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0025\n",
            "Epoch 27/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 28/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 29/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0019\n",
            "Epoch 30/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Epoch 31/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0015\n",
            "Epoch 32/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 33/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0013\n",
            "Epoch 34/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 35/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 36/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.3923e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.4328e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2734e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5200e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.9584e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.3136e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.7165e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 5.4031e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.1269e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6917e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6509e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3982e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.9110e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5735e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f2121015550>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([\n",
        "    [a, b] for _ in range(10)\n",
        "    for a, b in [(rnd.randint(1, 3), rnd.randint(1, 3))]\n",
        "    if a != b\n",
        "])\n",
        "\n",
        "Y_test = np.array([0 if a < b else 1 for a, b in X_test])  # правильные ответы\n",
        "\n",
        "y_pred = model.predict(X_test) # предсказания модели\n",
        "y_pred = (y_pred > 0.5).astype(int)  # преобразуем в 0 или 1\n",
        "\n",
        "errors = 0\n",
        "\n",
        "for i, prediction in enumerate(y_pred):\n",
        "    p1 = ['A', 'B', 'C'][X_test[i][0] - 1]\n",
        "    p2 = ['A', 'B', 'C'][X_test[i][1] - 1]\n",
        "    if prediction != Y_test[i]:\n",
        "        print(f\"Ошибка в игре {i+1}: {p1} против {p2}, победил не {p1 if prediction == 0 else p2}\")\n",
        "        errors += 1\n",
        "    else:\n",
        "        print(f\"Игра {i+1}: {p1} против {p2} => Победитель: {p1 if prediction == 0 else p2}\")\n",
        "\n",
        "print(f\"Процент ошибок: {((errors / len(Y_test)) * 100):.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_QvoL6yjhum",
        "outputId": "3054b80c-ccf7-4f10-e582-995819d9265a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
            "Игра 1: B против C => Победитель: B\n",
            "Игра 2: C против A => Победитель: A\n",
            "Игра 3: B против A => Победитель: A\n",
            "Игра 4: B против C => Победитель: B\n",
            "Игра 5: A против B => Победитель: A\n",
            "Игра 6: A против C => Победитель: A\n",
            "Игра 7: B против A => Победитель: A\n",
            "Процент ошибок: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Всё работает, отлично - модель научилась угадывать победителя. Теперь напишем, чтобы она сама участвовала в игре и выбирала себе героя."
      ],
      "metadata": {
        "id": "i7v22hosopeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "def reward(a, b):\n",
        "    return ([a, b] in [[0, 1], [0, 2], [1, 2]])\n",
        "\n",
        "# softmax модель\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(1,)),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "num_episodes = 300   # эпохи обучения\n",
        "steps_per_ep = 50    # матчей за одну эпоху\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    with tf.GradientTape() as tape:\n",
        "        state_input = tf.ones((steps_per_ep, 1), dtype=tf.float32)\n",
        "        probs = model(state_input, training=True)  # вероятности\n",
        ".\n",
        "        log_probs = tf.math.log(probs + 1e-6)\n",
        "\n",
        "        sampled_actions = tf.random.categorical(log_probs, num_samples=1) # ходы модели\n",
        "        sampled_actions = tf.squeeze(sampled_actions, axis=1)\n",
        "\n",
        "        rewards = []\n",
        "        for i in range(steps_per_ep):\n",
        "            model_hero = sampled_actions[i].numpy()\n",
        "            possible_opp = [x for x in [0,1,2] if x != model_hero]\n",
        "            opp_hero = np.random.choice(possible_opp)\n",
        "            rewards.append(reward(model_hero, opp_hero))\n",
        "\n",
        "        rewards = tf.constant(rewards, dtype=tf.float32)\n",
        "\n",
        "        chosen_action_log_p = tf.reduce_sum(\n",
        "            tf.one_hot(sampled_actions, depth=3) * log_probs,\n",
        "            axis=1\n",
        "        ) # корректируем модель\n",
        "        loss = -tf.reduce_mean(rewards * chosen_action_log_p)\n",
        "\n",
        "    # обновляем веса\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # статистика\n",
        "    if (episode + 1) % 20 == 0:\n",
        "        mean_reward = tf.reduce_mean(rewards)\n",
        "        print(f\"Episode {episode+1}/{num_episodes} | Mean reward: {mean_reward.numpy():.2f} | Loss: {loss.numpy():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kneotJNv2Q51",
        "outputId": "0d3b20ae-2de2-43f3-d71a-a49fbde1b2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20/300 | Mean reward: 0.46 | Loss: 0.509\n",
            "Episode 40/300 | Mean reward: 0.40 | Loss: 0.430\n",
            "Episode 60/300 | Mean reward: 0.56 | Loss: 0.522\n",
            "Episode 80/300 | Mean reward: 0.68 | Loss: 0.526\n",
            "Episode 100/300 | Mean reward: 0.86 | Loss: 0.440\n",
            "Episode 120/300 | Mean reward: 0.88 | Loss: 0.238\n",
            "Episode 140/300 | Mean reward: 0.96 | Loss: 0.259\n",
            "Episode 160/300 | Mean reward: 0.88 | Loss: 0.127\n",
            "Episode 180/300 | Mean reward: 0.96 | Loss: 0.120\n",
            "Episode 200/300 | Mean reward: 0.98 | Loss: 0.114\n",
            "Episode 220/300 | Mean reward: 0.98 | Loss: 0.186\n",
            "Episode 240/300 | Mean reward: 1.00 | Loss: 0.188\n",
            "Episode 260/300 | Mean reward: 0.98 | Loss: 0.026\n",
            "Episode 280/300 | Mean reward: 0.98 | Loss: 0.022\n",
            "Episode 300/300 | Mean reward: 1.00 | Loss: 0.020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Практика: смотрим, сколько матчей выиграет наша обученная модель"
      ],
      "metadata": {
        "id": "2AmhT2KWoTTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_test = 1000\n",
        "test_input = tf.ones((N_test, 1), dtype=tf.float32)\n",
        "test_probs = model(test_input, training=False)   # (N_test, 3)\n",
        "test_log_probs = tf.math.log(test_probs + 1e-10)\n",
        "test_actions = tf.random.categorical(test_log_probs, num_samples=1)\n",
        "test_actions = tf.squeeze(test_actions, axis=1).numpy()\n",
        "\n",
        "wins = 0\n",
        "for i in range(N_test):\n",
        "    L = ['A','B','C']\n",
        "    model_hero = test_actions[i]\n",
        "    opp_hero = np.random.choice([x for x in [0,1,2] if x != model_hero])\n",
        "    if reward(model_hero, opp_hero):\n",
        "        wins += 1\n",
        "        if i % 50 == 0:\n",
        "            print(f'Модель с героем {L[model_hero]} обыграла героя соперника {L[opp_hero]}')\n",
        "    else:\n",
        "        if i % 50 == 0:\n",
        "            print(f'x - Модель с героем {L[model_hero]} проиграла герою соперника {L[opp_hero]}')\n",
        "\n",
        "win_percent = 100.0 * wins / N_test\n",
        "print(f\"\\nИтоговая проверка: модель выиграла в {win_percent:.2f}% случаев.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl7uYZyvX68X",
        "outputId": "b058b1ac-935f-4362-d469-1b00bf53b665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "x - Модель с героем C проиграла герою соперника A\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "\n",
            "Итоговая проверка: модель выиграла в 98.10% случаев.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "УРААААА ГОООООЛ, он что-то выиграл.\n",
        "Это здорово, что он придумал невероятную тактику всегда выбирать героя А, но что, если правила С будет бить А, а не наоборот. Да и вообще, пора матрицу игр писать, ничью добавить...\n",
        "А ещё устроим дополнительную проверку модели на адекватность - нужно будет выбирать свой ход исходя из хода соперника (\"если у соперника ножницы, то очевидно нужен камень\", и т.д.)\n",
        "\n",
        "p.s. можно заметить, что это уже немного похоже на задачу, которую нам предстоит решить"
      ],
      "metadata": {
        "id": "kXFFnVSuXpyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ОБУЧЕНИЕ"
      ],
      "metadata": {
        "id": "o6F-aLIug90N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = [[0.5, 1, 0], [0, 0.5, 1], [1, 0, 0.5]]\n",
        "def reward(a, b):\n",
        "    return matrix[a][b]\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(1,)),\n",
        "    keras.layers.Embedding(input_dim=3, output_dim=4),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "num_episodes = 300   # эпохи обучения\n",
        "steps_per_ep = 50    # матчей за одну эпоху\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    with tf.GradientTape() as tape:\n",
        "        opp_hero = np.random.randint(0, 3, size=steps_per_ep)\n",
        "\n",
        "        state_input = tf.constant(opp_hero, dtype=tf.int32)\n",
        "        state_input = tf.reshape(state_input, (steps_per_ep, 1))\n",
        "        probs = model(state_input, training=True)\n",
        "        log_probs = tf.math.log(probs + 1e-6)\n",
        "\n",
        "        sampled_actions = tf.random.categorical(log_probs, num_samples=1)\n",
        "        sampled_actions = tf.squeeze(sampled_actions, axis=1)\n",
        "\n",
        "        rewards = []\n",
        "        for i in range(steps_per_ep):\n",
        "            model_hero = sampled_actions[i].numpy()\n",
        "            rewards.append(reward(model_hero, opp_hero[i]))\n",
        "\n",
        "        rewards = tf.constant(rewards, dtype=tf.float32)\n",
        "        chosen_action_log_p = tf.reduce_sum(\n",
        "            tf.one_hot(sampled_actions, depth=3) * log_probs,\n",
        "            axis=1\n",
        "        )\n",
        "        loss = -tf.reduce_mean(rewards * chosen_action_log_p)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    if (episode + 1) % 20 == 0:\n",
        "        mean_reward = tf.reduce_mean(rewards)\n",
        "        print(f\"Episode {episode+1}/{num_episodes} | Mean reward: {mean_reward.numpy():.2f} | Loss: {loss.numpy():.3f}\")"
      ],
      "metadata": {
        "id": "Y3QUObUzXtpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67998f1f-57ac-4916-e06c-6e21de43f585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20/300 | Mean reward: 0.52 | Loss: 0.437\n",
            "Episode 40/300 | Mean reward: 0.90 | Loss: 0.326\n",
            "Episode 60/300 | Mean reward: 0.96 | Loss: 0.033\n",
            "Episode 80/300 | Mean reward: 1.00 | Loss: 0.012\n",
            "Episode 100/300 | Mean reward: 0.99 | Loss: 0.056\n",
            "Episode 120/300 | Mean reward: 1.00 | Loss: 0.005\n",
            "Episode 140/300 | Mean reward: 1.00 | Loss: 0.004\n",
            "Episode 160/300 | Mean reward: 1.00 | Loss: 0.003\n",
            "Episode 180/300 | Mean reward: 1.00 | Loss: 0.002\n",
            "Episode 200/300 | Mean reward: 1.00 | Loss: 0.002\n",
            "Episode 220/300 | Mean reward: 1.00 | Loss: 0.001\n",
            "Episode 240/300 | Mean reward: 1.00 | Loss: 0.001\n",
            "Episode 260/300 | Mean reward: 1.00 | Loss: 0.001\n",
            "Episode 280/300 | Mean reward: 1.00 | Loss: 0.001\n",
            "Episode 300/300 | Mean reward: 1.00 | Loss: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ПРОВЕРКА"
      ],
      "metadata": {
        "id": "TJWWu168hAq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N_test = 1000\n",
        "opp_hero_test = np.random.randint(0,3, size=N_test)\n",
        "test_input = tf.constant(opp_hero_test, dtype=tf.int32)\n",
        "test_input = tf.reshape(test_input, (N_test, 1))\n",
        "\n",
        "test_probs = model(test_input, training=False)  # (N_test,3)\n",
        "test_log_probs = tf.math.log(test_probs + 1e-6)\n",
        "test_actions = tf.random.categorical(test_log_probs, num_samples=1)\n",
        "test_actions = tf.squeeze(test_actions, axis=1).numpy()\n",
        "\n",
        "wins = 0\n",
        "L = ['A','B','C']\n",
        "for i in range(N_test):\n",
        "    model_hero = test_actions[i]\n",
        "    opp_hero = opp_hero_test[i]\n",
        "    r = reward(model_hero, opp_hero)\n",
        "    wins += r\n",
        "    if i % 50 == 0 or r < 1:\n",
        "        if r == 1.0:\n",
        "            print(f'Модель с героем {L[model_hero]} обыграла героя соперника {L[opp_hero]}')\n",
        "        elif r:\n",
        "            print(f'Модель с героем {L[model_hero]} сыграла вничью с героем соперника {L[opp_hero]}')\n",
        "        else:\n",
        "            print(f'x - Модель с героем {L[model_hero]} проиграла герою соперника {L[opp_hero]}')\n",
        "\n",
        "win_percent = 100.0 * wins / N_test\n",
        "print(f\"\\nИтоговая проверка: модель выиграла в {win_percent:.2f}% матчей.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vyt-_Ndhg88n",
        "outputId": "c4ec9051-0bcb-4b2a-8463-e27cce33873e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A сыграла вничью с героем соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "x - Модель с героем A проиграла герою соперника C\n",
            "Модель с героем B обыграла героя соперника C\n",
            "Модель с героем C обыграла героя соперника A\n",
            "Модель с героем A обыграла героя соперника B\n",
            "Модель с героем B обыграла героя соперника C\n",
            "\n",
            "Итоговая проверка: модель выиграла в 99.85% матчей.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Потрясающе, какие мы молодцы.\n",
        "Теперь представим, что героев у нас не 3, а там, 200. А ещё мы живём в реальном мире, где и везде и повсюду вероятности, так что есть шанс у героя в неравной схватке с другим изредка выйти победителем.\n",
        "\n",
        "Все эти вероятности мы учтём в нашей матрице, а после этого проверим нашу модель на работоспособность в самых что ни на есть боевых условиях"
      ],
      "metadata": {
        "id": "MO7LPKoNnLPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hero_number = 200\n",
        "matrix = [[rnd.random() * 0.8 for _ in range(hero_number)] for __ in range(hero_number)]\n",
        "for i in range(hero_number):\n",
        "    matrix[i][i] = 0.5\n",
        "    for j in range(i+1, hero_number):\n",
        "        matrix[i][j] = 1 - matrix[j][i]\n",
        "\n",
        "'''for i in range(hero_number):\n",
        "    for j in range(hero_number):\n",
        "        print(round(matrix[i][j], 2), end = ' ')\n",
        "    print()'''\n",
        "\n",
        "def reward(a, b):\n",
        "    return 1 if rnd.random() < matrix[a][b] else 0"
      ],
      "metadata": {
        "id": "KpPXUTM_nJNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Input(shape=(1,)),\n",
        "    keras.layers.Embedding(input_dim=hero_number, output_dim=hero_number+1),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(hero_number, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "num_episodes = 300   # эпохи обучения\n",
        "steps_per_ep = 500    # матчей за одну эпоху\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    with tf.GradientTape() as tape:\n",
        "        opp_hero = np.random.randint(0, hero_number, size=steps_per_ep)\n",
        "\n",
        "        state_input = tf.constant(opp_hero, dtype=tf.int32)\n",
        "        state_input = tf.reshape(state_input, (steps_per_ep, 1))\n",
        "        probs = model(state_input, training=True)\n",
        "        log_probs = tf.math.log(probs + 1e-10)\n",
        "\n",
        "        sampled_actions = tf.random.categorical(log_probs, num_samples=1)\n",
        "        sampled_actions = tf.squeeze(sampled_actions, axis=1)\n",
        "\n",
        "        rewards = []\n",
        "        for i in range(steps_per_ep):\n",
        "            model_hero = sampled_actions[i].numpy()\n",
        "            rewards.append(reward(model_hero, opp_hero[i]))\n",
        "\n",
        "        rewards = tf.constant(rewards, dtype=tf.float32)\n",
        "        chosen_action_log_p = tf.reduce_sum(\n",
        "            tf.one_hot(sampled_actions, depth=hero_number) * log_probs,\n",
        "            axis=1\n",
        "        )\n",
        "        loss = -tf.reduce_mean(rewards * chosen_action_log_p)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    if (episode + 1) % 20 == 0:\n",
        "        mean_reward = tf.reduce_mean(rewards)\n",
        "        print(f\"Episode {episode+1}/{num_episodes} | Mean reward: {mean_reward.numpy():.2f} | Loss: {loss.numpy():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QPyBBrkq-ma",
        "outputId": "6050e062-f477-48e6-ef09-70c2364e8bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 20/300 | Mean reward: 0.48 | Loss: 2.546\n",
            "Episode 40/300 | Mean reward: 0.52 | Loss: 2.725\n",
            "Episode 60/300 | Mean reward: 0.52 | Loss: 2.675\n",
            "Episode 80/300 | Mean reward: 0.57 | Loss: 2.874\n",
            "Episode 100/300 | Mean reward: 0.58 | Loss: 2.570\n",
            "Episode 120/300 | Mean reward: 0.63 | Loss: 2.040\n",
            "Episode 140/300 | Mean reward: 0.75 | Loss: 1.234\n",
            "Episode 160/300 | Mean reward: 0.81 | Loss: 0.766\n",
            "Episode 180/300 | Mean reward: 0.83 | Loss: 0.387\n",
            "Episode 200/300 | Mean reward: 0.85 | Loss: 0.204\n",
            "Episode 220/300 | Mean reward: 0.85 | Loss: 0.080\n",
            "Episode 240/300 | Mean reward: 0.85 | Loss: 0.047\n",
            "Episode 260/300 | Mean reward: 0.86 | Loss: 0.025\n",
            "Episode 280/300 | Mean reward: 0.86 | Loss: 0.025\n",
            "Episode 300/300 | Mean reward: 0.85 | Loss: 0.038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_test = 1000\n",
        "print(hero_number)\n",
        "opp_hero_test = np.random.randint(0,3, size=N_test)\n",
        "test_input = tf.constant(opp_hero_test, dtype=tf.int32)\n",
        "test_input = tf.reshape(test_input, (N_test, 1))\n",
        "\n",
        "test_probs = model(test_input, training=False)  # (N_test,3)\n",
        "test_log_probs = tf.math.log(test_probs + 1e-10)\n",
        "test_actions = tf.random.categorical(test_log_probs, num_samples=1)\n",
        "test_actions = tf.squeeze(test_actions, axis=1).numpy()\n",
        "\n",
        "wins = 0\n",
        "L = [chr(i + 100) for i in range(hero_number)]\n",
        "for i in range(N_test):\n",
        "    model_hero = test_actions[i]\n",
        "    opp_hero = opp_hero_test[i]\n",
        "    r = reward(model_hero, opp_hero)\n",
        "    wins += r\n",
        "    if i % 50 == 0:\n",
        "        if r:\n",
        "            print(f'Модель с героем {L[model_hero]} обыграла героя соперника {L[opp_hero]}')\n",
        "        else:\n",
        "            print(f'x - Модель с героем {L[model_hero]} проиграла герою соперника {L[opp_hero]}')\n",
        "\n",
        "win_percent = 100.0 * wins / N_test\n",
        "print(f\"\\nИтоговая проверка: модель выиграла в {win_percent:.2f}% матчей.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku0oD70arvzC",
        "outputId": "55af3ceb-2a67-4e50-d0b9-b33d04c6e1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n",
            "x - Модель с героем   проиграла герою соперника f\n",
            "Модель с героем é обыграла героя соперника d\n",
            "Модель с героем ĩ обыграла героя соперника e\n",
            "Модель с героем ĩ обыграла героя соперника e\n",
            "Модель с героем   обыграла героя соперника f\n",
            "Модель с героем   обыграла героя соперника f\n",
            "Модель с героем é обыграла героя соперника d\n",
            "Модель с героем ĩ обыграла героя соперника e\n",
            "Модель с героем   обыграла героя соперника f\n",
            "Модель с героем   обыграла героя соперника f\n",
            "Модель с героем ĩ обыграла героя соперника e\n",
            "x - Модель с героем   проиграла герою соперника f\n",
            "Модель с героем ĩ обыграла героя соперника e\n",
            "Модель с героем   обыграла героя соперника f\n",
            "x - Модель с героем é проиграла герою соперника d\n",
            "x - Модель с героем é проиграла герою соперника d\n",
            "x - Модель с героем ĩ проиграла герою соперника e\n",
            "Модель с героем é обыграла героя соперника d\n",
            "Модель с героем ĩ обыграла героя соперника e\n",
            "Модель с героем ĩ обыграла героя соперника e\n",
            "\n",
            "Итоговая проверка: модель выиграла в 76.50% матчей.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выгрузим данные из файла"
      ],
      "metadata": {
        "id": "DK4R5OhpRc-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "with open('matrix.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "matrix = ast.literal_eval(lines[0].strip())\n",
        "hero_names = ast.literal_eval(lines[1].strip())\n",
        "hero_names_rev = ast.literal_eval(lines[2].strip())\n",
        "\n",
        "print(\"Matrix:\")\n",
        "print(matrix)\n",
        "\n",
        "print(\"\\nHero Names:\")\n",
        "print(hero_names)\n",
        "\n",
        "print(\"\\nHero Names Reverse:\")\n",
        "print(hero_names_rev)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCHNzozfRftG",
        "outputId": "3400bbb3-fdd9-4739-c128-99b078715cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix:\n",
            "[[0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 0, 0.0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 0.5, 0, 1.0, 0, 0, 0.0, 0.0, 0, 1.0, 0, 0.0, 0, 0, 1.0, 0, 0, 0, 0.0, 0.5, 0.0, 0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 1.0, 0, 0.6666666666666666, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0.0, 0.5, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 1.0, 1.0, 0, 0, 0, 1.0, 0, 0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0.0, 0, 0, 0.0, 0.0, 0, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0.0, 1.0, 1.0, 0, 1.0, 0, 0.5, 0.0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0.0, 0.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 1.0, 0.5, 0, 0.0, 0, 0, 0, 0, 0, 0, 1.0, 0.0, 0.0, 0, 0, 1.0, 1.0, 1.0], [0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.3333333333333333, 0, 1.0, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0.5, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0], [0, 0, 0, 1.0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 1.0, 0.6666666666666666, 0, 0.0, 0, 0, 1.0, 0.5, 0.5, 1.0, 0, 0.5, 0, 0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0, 0.0, 1.0, 0, 0, 1.0, 0.6666666666666666, 0, 1.0, 0.5, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 1.0, 1.0, 0, 0.5, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0.0, 0, 1.0, 0, 1.0, 0, 0, 0, 1.0, 1.0, 1.0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 1.0, 0.5, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0.0, 0.5, 0.0, 0.0, 0, 0.0, 0, 0, 0, 0.0, 0, 0, 1.0, 0, 0, 0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 1.0, 0.0, 0.0, 0.0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 1.0, 0, 0, 0, 1.0, 0, 0, 0, 1.0, 1.0, 0.5, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0.0, 1.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 1.0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 1.0, 1.0, 0, 1.0, 0.5, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0.5, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0.0, 0, 0, 0.0, 1.0, 0.5, 1.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0.0, 0, 1.0, 0, 0, 0, 1.0, 0, 0, 0, 0.5, 0, 0, 0.0, 1.0, 0.5, 1.0, 0, 1.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 0.5, 0, 0, 0, 0.0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 1.0, 0, 0.0, 0, 1.0, 1.0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 1.0, 1.0, 1.0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 1.0, 0, 0, 0], [0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0], [0, 0.0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 1.0, 0.0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.5, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0.0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0.6666666666666666, 1.0, 1.0, 0, 0, 0, 0, 0, 0.0, 0, 0, 1.0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 1.0, 0.0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0.5, 1.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0], [0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0.0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 1.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0.5, 0.0, 0, 0, 0.0, 0, 0.0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0.3333333333333333, 0.0, 0.0, 0.0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0.0, 0.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0], [0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 1.0, 0, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1.0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 1.0, 1.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0.0, 1.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3333333333333333, 0, 0, 0, 0, 0, 0, 0, 0.5, 0, 0.5, 0, 0, 0.0, 0, 0, 0, 1.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0], [0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 1.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 1.0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 1.0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 1.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.0, 0, 0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "\n",
            "Hero Names:\n",
            "{'Crystal Maiden': 0, 'Meepo': 1, 'Elder Titan': 2, 'Bristleback': 3, 'Death Prophet': 4, 'Slark': 5, 'Huskar': 6, 'Clockwerk': 7, 'Witch Doctor': 8, 'Underlord': 9, 'Sand King': 10, 'Pudge': 11, 'Pugna': 12, 'Morphling': 13, 'Muerta': 14, 'Lina': 15, 'Bloodseeker': 16, 'Kunkka': 17, 'Lich': 18, 'Sniper': 19, 'Drow Ranger': 20, 'Phantom Assassin': 21, 'Ogre Magi': 22, 'Queen of Pain': 23, 'Disruptor': 24, 'Shadow Shaman': 25, 'Windranger': 26, 'Rubick': 27, 'Zeus': 28, 'Arc Warden': 29, 'Juggernaut': 30, 'Enigma': 31, 'Tinker': 32, 'Spirit Breaker': 33, 'Weaver': 34, 'Mirana': 35, 'Riki': 36, 'Abaddon': 37, 'Timbersaw': 38, 'Viper': 39, 'Legion Commander': 40, 'Anti-Mage': 41, 'Dazzle': 42, 'Spectre': 43, 'Ancient Apparition': 44, 'Ursa': 45, 'Earthshaker': 46, 'Phantom Lancer': 47, 'Bounty Hunter': 48, 'Lion': 49, 'Invoker': 50, 'Magnus': 51, 'Oracle': 52, 'Hoodwink': 53, 'Skywrath Mage': 54, 'Storm Spirit': 55, 'Luna': 56, 'Venomancer': 57, 'Clinkz': 58, 'Shadow Fiend': 59, 'Brewmaster': 60, \"Nature's Prophet\": 61, 'Snapfire': 62, 'Techies': 63, 'Grimstroke': 64, 'Wraith King': 65, 'Earth Spirit': 66, 'Io': 67, 'Dark Willow': 68, 'Vengeful Spirit': 69, 'Axe': 70, 'Jakiro': 71, 'Puck': 72, 'Gyrocopter': 73, 'Templar Assassin': 74, 'Primal Beast': 75, 'Razor': 76, 'Lone Druid': 77, 'Nyx Assassin': 78, 'Tidehunter': 79, 'Dragon Knight': 80, 'Phoenix': 81, 'Dawnbreaker': 82, 'Doom': 83, 'Chaos Knight': 84, 'Warlock': 85}\n",
            "\n",
            "Hero Names Reverse:\n",
            "['Crystal Maiden', 'Meepo', 'Elder Titan', 'Bristleback', 'Death Prophet', 'Slark', 'Huskar', 'Clockwerk', 'Witch Doctor', 'Underlord', 'Sand King', 'Pudge', 'Pugna', 'Morphling', 'Muerta', 'Lina', 'Bloodseeker', 'Kunkka', 'Lich', 'Sniper', 'Drow Ranger', 'Phantom Assassin', 'Ogre Magi', 'Queen of Pain', 'Disruptor', 'Shadow Shaman', 'Windranger', 'Rubick', 'Zeus', 'Arc Warden', 'Juggernaut', 'Enigma', 'Tinker', 'Spirit Breaker', 'Weaver', 'Mirana', 'Riki', 'Abaddon', 'Timbersaw', 'Viper', 'Legion Commander', 'Anti-Mage', 'Dazzle', 'Spectre', 'Ancient Apparition', 'Ursa', 'Earthshaker', 'Phantom Lancer', 'Bounty Hunter', 'Lion', 'Invoker', 'Magnus', 'Oracle', 'Hoodwink', 'Skywrath Mage', 'Storm Spirit', 'Luna', 'Venomancer', 'Clinkz', 'Shadow Fiend', 'Brewmaster', \"Nature's Prophet\", 'Snapfire', 'Techies', 'Grimstroke', 'Wraith King', 'Earth Spirit', 'Io', 'Dark Willow', 'Vengeful Spirit', 'Axe', 'Jakiro', 'Puck', 'Gyrocopter', 'Templar Assassin', 'Primal Beast', 'Razor', 'Lone Druid', 'Nyx Assassin', 'Tidehunter', 'Dragon Knight', 'Phoenix', 'Dawnbreaker', 'Doom', 'Chaos Knight', 'Warlock']\n"
          ]
        }
      ]
    }
  ]
}